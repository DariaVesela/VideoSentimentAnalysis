{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from videosentimentanalysis.usecases.download_video_use_case import VideoUseCase\n",
    "from videosentimentanalysis.adapters.logging.custom_logger import CustomLogger\n",
    "from videosentimentanalysis.adapters.logging.loguru_logger import LoguruLogger\n",
    "from videosentimentanalysis.adapters.extract_audio.moviepy_extraction import MoviePyAudioExtractor\n",
    "from videosentimentanalysis.usecases.video_utility_use_case import VideoUtilityUseCase\n",
    "from videosentimentanalysis.adapters.transcribe_audio.speechrecognition import SpeechRecognition\n",
    "from videosentimentanalysis.adapters.perform_sentiment_analysis.textblob_analysis import TextBlobAnalysis\n",
    "from videosentimentanalysis.adapters.translate_text.google_translate import TextTranslation\n",
    "from videosentimentanalysis.usecases.protocols.translate_text import LanguageOptions\n",
    "from videosentimentanalysis.adapters.extract_emotions.text2emotion_extractor import GetEmotions\n",
    "from videosentimentanalysis.domain.audio import Audio\n",
    "import json\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc42bf628fc94b43"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER= Path(\"./output/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e83aeaa3cf9d64c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "To run this project you need to have the following installed:\n",
    "- ffmpeg\n",
    "- python3.12\n",
    "- poetry"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff0c34a28abcf980"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Adapters\n",
    "### Logging\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8303710cc04978e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_logger = CustomLogger(Path(\"./download_log.txt\"))\n",
    "loguru_logger = LoguruLogger(Path(\"./loguru_logger.log\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91558f9537c3b5d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Video Utilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad6290ebef44631"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "moviepy_extractor = MoviePyAudioExtractor(Path(\"./tmp_audio\"))\n",
    "speechrecognition = SpeechRecognition()\n",
    "sentimentanalysis = TextBlobAnalysis()\n",
    "text_translation = TextTranslation()\n",
    "emotion_extraction = GetEmotions()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf07402fe85cda53",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load all the Youtube URLs to a Pydantic Model called RawURLVideo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebbf29a912f67693"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "video_use_case = VideoUseCase(video_output_directory=Path(\"tmp_videos\"), logger=custom_logger)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb51a42197fc85d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "raw_url_videos=video_use_case.load_raw_url_video(Path('./video_urls.txt'))\n",
    "raw_url_videos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a644f01e9f56bc33",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sequential_time_taken = time()\n",
    "video_use_case.download_raw_videos_sequentially(raw_url_videos)\n",
    "sequential_time_taken = time() - sequential_time_taken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546d5e8579d1d74b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "threading_time_taken = time()\n",
    "video_use_case.download_raw_videos_threading(raw_url_videos)\n",
    "threading_time_taken = time() - threading_time_taken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a17e12ba92a8dae7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "process_time_taken = time()\n",
    "videos=video_use_case.download_raw_videos_multiprocessing(raw_url_videos)\n",
    "process_time_taken = time() - process_time_taken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "286f7c4ea19470d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results of each method for downloading videos and time taken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1543d56c85aa743a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Method\": [\"Sequential\", \"Threading\", \"Multiprocessing\"],\n",
    "    \"Time Taken\": [sequential_time_taken, threading_time_taken, process_time_taken]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88f7f5ac315eb96",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above shows the difference in performance when used downloading videos sequentially, using threading or multiprocessing. Unsurprisingly, the sequential method is the slowest. As this is a CPU bound task, the multiprocessing method is the quickest one."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf12ddfd57466ce7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for video_index in range(len(videos)):\n",
    "    video=videos[video_index]\n",
    "    video_utlity_use_case=VideoUtilityUseCase(video=video, logger=custom_logger, extract_audio=moviepy_extractor, extract_text=speechrecognition, extract_polarity_and_sensitivity=sentimentanalysis, translate=text_translation,extract_emotions=emotion_extraction)\n",
    "    \n",
    "    video_output_folder= OUTPUT_FOLDER / video.title\n",
    "    video_output_folder.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    video.move(video_output_folder)\n",
    "    print(video.local_storage_path)\n",
    "    \n",
    "    audio = video_utlity_use_case.extract_audio()\n",
    "    audio.move(video_output_folder)\n",
    "    \n",
    "    with open(video_output_folder / \"sentimental_analysis.json\", mode=\"w\") as sentimental_analysis_file:\n",
    "        sentimental_analysis_file.write(json.dumps(video_utlity_use_case.get_sentiment_analysis()))\n",
    "    \n",
    "    with open(video_output_folder / \"transcribe_text.txt\", mode=\"w\") as transcribe_text_file:\n",
    "        transcribe_text_file.write(video_utlity_use_case.transcribe_audio())\n",
    "    \n",
    "    with open(video_output_folder / \"translate_text.txt\", mode=\"w\") as translate_text_file:\n",
    "        translate_text_file.write(video_utlity_use_case.translate_text(source_lang=LanguageOptions.ENGLISH, target_lang=LanguageOptions.SPANISH))\n",
    "    \n",
    "    with open(video_output_folder / \"detect_emotions.json\", mode=\"w\") as detect_emotions_file:\n",
    "        detect_emotions_file.write(json.dumps(video_utlity_use_case.detect_emotions()))\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eb488471353c116",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sequential time for extract audio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1662057c8cfdb663"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "videos=video_use_case.download_raw_videos_multiprocessing(raw_url_videos)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e6a73b0ba42c8d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extract_audio_time_seq = time()\n",
    "for video in videos:\n",
    "    video_utlity_use_case=VideoUtilityUseCase(video=video, logger=custom_logger, extract_audio=moviepy_extractor, extract_text=speechrecognition, extract_polarity_and_sensitivity=sentimentanalysis, translate=text_translation,extract_emotions=emotion_extraction)\n",
    "    video_utlity_use_case.extract_audio()\n",
    "\n",
    "extract_audio_time_seq = time() -extract_audio_time_seq\n",
    "print(f\"Time taken for sequential extraction is {extract_audio_time_seq} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8c6aaf2d25c53e0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Threading time for extract audio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9004dea6fcc1553e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def threading_wrapper_extractor(results: list[Audio],index: int,video_utlity_use_case :  VideoUtilityUseCase):\n",
    "    custom_logger.log(f\"Processing {video_utlity_use_case.video.title} on thread {index}\")\n",
    "    results[index]=video_utlity_use_case.extract_audio()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b5d33c5f4ebe193",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extract_audio_time_threading = time()\n",
    "results = [None] * len(videos)\n",
    "threads = []\n",
    "for index, video in enumerate(videos):\n",
    "    video_utlity_use_case= VideoUtilityUseCase(video=video, logger=custom_logger, extract_audio=moviepy_extractor, extract_text=speechrecognition, extract_polarity_and_sensitivity=sentimentanalysis, translate=text_translation,extract_emotions=emotion_extraction)\n",
    "    thread = Thread(target=threading_wrapper_extractor, args=(results,index,video_utlity_use_case))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "extract_audio_time_threading = time() -extract_audio_time_threading\n",
    "print(f\"Time taken for threading extraction is {extract_audio_time_threading} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "993ad3dd3d375712",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing time for extract audio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36180cdf94cc1694"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extract_audio_time_processes = time()\n",
    "manager = Manager()\n",
    "results = manager.list([None] * len(videos))\n",
    "processes = []\n",
    "for index, video in enumerate(videos):\n",
    "    video_utlity_use_case= VideoUtilityUseCase(video=video, logger=custom_logger, extract_audio=moviepy_extractor, extract_text=speechrecognition, extract_polarity_and_sensitivity=sentimentanalysis, translate=text_translation,extract_emotions=emotion_extraction)\n",
    "    process = Process(target=video_utlity_use_case._multiprocessing_wrapper_audio_extraction_wrapper, args=(results,index))\n",
    "    processes.append(process)\n",
    "    process.start()\n",
    "for process in processes:\n",
    "    process.join()\n",
    "extract_audio_time_processes = time() -extract_audio_time_processes\n",
    "print(f\"Time taken for processing extraction is {extract_audio_time_processes} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23bd0985fa442764",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison of sequential, threading, multiprocessing for extracting audio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7c574e0986e569a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Method\": [\"Sequential\", \"Threading\", \"Multiprocessing\"],\n",
    "    \"Time Taken\": [extract_audio_time_seq, extract_audio_time_threading, extract_audio_time_processes]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a677d3af11e1a647",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Short Report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce47f3154cfca736"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b076fec979b34641"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CineSense Project Implementation:\n",
    "\n",
    "\n",
    "## Architecture\n",
    "\n",
    "I’ve selected the hexagonal (also called ports and adapters) architecture for this project as it is widely used in industry settings due to its scalability and reusability. It has been used by Netflix to manage their flow of large amounts of data from different sources due to its ability to  swap data sources without impacting business logic (Damir Svrtan 2020). \n",
    "The architecture breaks the program down into Domain, Services, Use cases and Adapters. The Domain is the broad data that we’re working with – in this case YouTube videos and their content. Services represent the results we want to obtain from the domain – in this case a Jupyter file which presents the log of what we did with the data, and the #1 downloaded videos, #2 transcribed audio, #3 sentiment analysis, #4 emotion extraction and #5 text translation into Spanish – the result of which can be found in the output files. Because the actual implementation – which lives in the adapters folder – is decoupled from the business logic, the application can be easily maintained should the requirements change – e.g. if we want to use a different library to extract emotions, we simply modify the adapter. \n",
    "\n",
    "## Use cases\n",
    "\n",
    "There are two major use cases: the actual downloading of the YouTube videos and the actions we can perform on the content, such as sentiment analysis. I have enveloped the actions into a single use case called utilities to separate the obtaining of the data and the analysis of the data. \n",
    "Downloading Videos\n",
    "Downloading videos only requires one method. I have compared the speed of download for sequential download, threading and multiprocessing. The results of this can be found in the pandas data frame in the Jupyter file. Unsurprisingly, the sequential method is the least efficient. The multiprocessing method is the most efficient, as this is a CPU bound task and multiprocessing is taking advantage of multi-core processors and processes downloads in parallel. The time saving is evident, as multiprocessing is roughly 4x quicker than sequential download in this case. Threading also brings a much improved result compared to sequential download, however, as this is not an I/O bound task, it is less efficient than multiprocessing. \n",
    "\n",
    "## Analysing Videos\n",
    "The video analysis consists of extracting audio, transcribing audio, extracting sentiment analysis and extracting emotions. I have used the MoviePy library for extracting the audio and speechrecognition for transcribing it. For extracting emotions I’ve used the text2emotion library, for sentiment analysis I’ve used the TextBlob library (returning the polarity and sensitivity) and for translation I’ve relied on Google Translate. The results for each video can be found in the respective folder, labelled according to the name of the video. \n",
    "As the extract emotions, extract sentiment analysis and translate methods repeatedly rely on the results of the extract audio and transcribe audio methods, I have used caching to store the extracted and transcribed audio, which significantly increased the overall speed of the program. \n",
    "I have also compared the sequential, threading and multiprocessing methods for extracting audio. Once again, the multiprocessing method is the most efficient due to its suitability for CPU bound tasks. Surprisingly, the sequential method performed marginally better than the threading method. There is a variety of possible reasons for this, with a likely one being that threading creates a lot of overhead in terms of managing context switching and synchronization. Furthermore, threads working on extracting one audio might lead to contention for resources, which is avoided when using the sequential method. \n",
    "\n",
    "## Logging\n",
    "\n",
    "I have implemented a simple logger to inform the user regarding the state of the processing of individual videos, as well as any potential errors. \n",
    "There is also the option to use loguru for a more scaled up logging experience. \n",
    "\n",
    "\n",
    "## Works Cited\n",
    "Damir Svrtan, Sergii Makagon. 2020. Netflix Technology Blog. 10 March. Accessed June 24, 2024. https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a7c71aa53ed6c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "361f0a8ec6933103"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
